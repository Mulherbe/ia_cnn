{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":42685,"status":"ok","timestamp":1684140509470,"user":{"displayName":"Fred Mu","userId":"08480376312364057880"},"user_tz":-120},"id":"8RJDZDGEJMun","outputId":"ce7d2c2d-a5d4-4cb3-d514-dcff165b982b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Images extraites avec succès.\n","Images extraites avec succès.\n","Images extraites avec succès.\n"]}],"source":["# faire du auguementation de data (changement de lumi...)\n","#faceapi framework python\n","#faire de la doc\n","# teste\n","#mlops (re entrainé son ia)\n","# cold storage / hot storage / data warehouse \n","#bucket google , s3 amazon\n","\n","import urllib.request\n","import zipfile\n","import io\n","\n","# URL du fichier zip contenant les images\n","url = \"https://github.com/Fred-shenron/ia_img/raw/main/train.zip\"\n","\n","# # Télécharger le fichier zip et extraire les images\n","with urllib.request.urlopen(url) as url_response:\n","    with zipfile.ZipFile(io.BytesIO(url_response.read())) as zip_file:\n","      zip_file.extractall()\n","      print(\"Images extraites avec succès.\")\n","\n","urlTest = \"https://github.com/Fred-shenron/ia_img/raw/main/test.zip\"\n","\n","# Télécharger le fichier zip et extraire les images\n","with urllib.request.urlopen(urlTest) as url_response:\n","    with zipfile.ZipFile(io.BytesIO(url_response.read())) as zip_file:\n","        zip_file.extractall()\n","        print(\"Images extraites avec succès.\")\n","\n","urlVal= \"https://github.com/Fred-shenron/ia_img/raw/main/val.zip\"\n","\n","# Télécharger le fichier zip et extraire les images\n","with urllib.request.urlopen(urlVal) as url_response:\n","    with zipfile.ZipFile(io.BytesIO(url_response.read())) as zip_file:\n","        zip_file.extractall()\n","        print(\"Images extraites avec succès.\")\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4461,"status":"ok","timestamp":1684140518196,"user":{"displayName":"Fred Mu","userId":"08480376312364057880"},"user_tz":-120},"id":"F92muiwsJ5SJ","outputId":"83b6b926-2444-4c09-8c04-ece3ba61869f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 7618 images belonging to 3 classes.\n","Found 788 images belonging to 3 classes.\n","Found 26 images belonging to 3 classes.\n"]}],"source":["import urllib.request\n","import zipfile\n","import io\n","import os\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","# Votre code d'importation des images ici\n","\n","# Chemins vers les dossiers d'images\n","train_dir = \"train\"\n","test_dir = \"test\"\n","val_dir = \"val\"\n","\n","# Prétraitement des images\n","train_datagen = ImageDataGenerator(rescale=1./255)\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","val_datagen = ImageDataGenerator(rescale=1./255)\n","\n","# Générateurs d'images\n","train_generator = train_datagen.flow_from_directory(train_dir, target_size=(150, 150), batch_size=32, class_mode='categorical',)\n","test_generator = test_datagen.flow_from_directory(test_dir, target_size=(150, 150), batch_size=32, class_mode=\"categorical\")\n","val_generator = val_datagen.flow_from_directory(val_dir, target_size=(150, 150), batch_size=32, class_mode=\"categorical\")\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"qwZQKkfgKEag","executionInfo":{"status":"ok","timestamp":1684140532964,"user_tz":-120,"elapsed":3806,"user":{"displayName":"Fred Mu","userId":"08480376312364057880"}}},"outputs":[],"source":["# Construction du modèle CNN\n","model = Sequential([\n","    Conv2D(32, (3, 3), activation=\"relu\", input_shape=(150, 150, 3)),\n","    MaxPooling2D(2, 2),\n","    Conv2D(64, (3, 3), activation=\"relu\"),\n","    MaxPooling2D(2, 2),\n","    Conv2D(128, (3, 3), activation=\"relu\"),\n","    MaxPooling2D(2, 2),\n","    Flatten(),\n","    Dense(512, activation=\"relu\"),\n","    Dropout(0.5),\n","    Dense(3, activation=\"softmax\")  # Modifiez cette ligne\n","])\n","\n","# Compilation du modèle\n","model.compile(optimizer=Adam(learning_rate=0.001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])  # Modifiez cette ligne\n","\n","early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DUWgy6V6KH4K","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6d1ce637-52f8-4527-db51-4eb42b3a950c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","239/239 [==============================] - 83s 300ms/step - loss: 0.2495 - accuracy: 0.9153 - val_loss: 0.2293 - val_accuracy: 0.8846\n","Epoch 2/20\n","239/239 [==============================] - 70s 293ms/step - loss: 0.0933 - accuracy: 0.9664 - val_loss: 0.1284 - val_accuracy: 0.9615\n","Epoch 3/20\n","239/239 [==============================] - 71s 295ms/step - loss: 0.0893 - accuracy: 0.9664 - val_loss: 0.1526 - val_accuracy: 0.9615\n","Epoch 4/20\n","239/239 [==============================] - 71s 296ms/step - loss: 0.0693 - accuracy: 0.9768 - val_loss: 0.3592 - val_accuracy: 0.8077\n","Epoch 5/20\n","239/239 [==============================] - 71s 299ms/step - loss: 0.0403 - accuracy: 0.9857 - val_loss: 0.0680 - val_accuracy: 0.9615\n","Epoch 6/20\n","239/239 [==============================] - 70s 292ms/step - loss: 0.0332 - accuracy: 0.9871 - val_loss: 0.1208 - val_accuracy: 0.9231\n","Epoch 7/20\n","239/239 [==============================] - 70s 294ms/step - loss: 0.0272 - accuracy: 0.9909 - val_loss: 0.0711 - val_accuracy: 0.9231\n","Epoch 8/20\n","239/239 [==============================] - 70s 292ms/step - loss: 0.0328 - accuracy: 0.9882 - val_loss: 0.0526 - val_accuracy: 0.9615\n","Epoch 9/20\n","  6/239 [..............................] - ETA: 1:32 - loss: 0.0392 - accuracy: 0.9844"]}],"source":["# Entraînement du modèle\n","history = model.fit(train_generator, epochs=20, validation_data=val_generator, callbacks=[early_stopping])\n","\n","# Évaluation du modèle\n","test_loss, test_accuracy = model.evaluate(test_generator)\n","print(f\"Test accuracy: {test_accuracy}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S6QqD7LTPSFE"},"outputs":[],"source":["# Afficher les images avec leurs prédictions et leurs labels\n","\n","import math\n","\n","def display_image_predictions(images, true_labels, predictions):\n","    num_images = len(images)\n","    grid_size = math.ceil(math.sqrt(num_images))\n","    \n","    fig, axes = plt.subplots(grid_size, grid_size, figsize=(15, 15))\n","    fig.subplots_adjust(hspace=0.5, wspace=0.5)\n","\n","    for i, (img, true_label, pred) in enumerate(zip(images, true_labels, predictions)):\n","        row, col = divmod(i, grid_size)\n","        axes[row, col].imshow(img)\n","        axes[row, col].set_title(f\"Vraie catégorie : {true_label}\\nPrédiction : {pred}\")\n","        axes[row, col].axis('off')\n","\n","    # Masquer les axes inutilisés\n","    for j in range(i + 1, grid_size * grid_size):\n","        row, col = divmod(j, grid_size)\n","        axes[row, col].axis('off')\n","\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZjBQkS3nREYB"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","# Évaluer le modèle sur l'ensemble de test\n","test_loss, test_acc = model.evaluate(test_generator)\n","print('Accuracy on test set:', test_acc)\n","\n","# Créer un graphique pour afficher les résultats\n","fig, ax = plt.subplots()\n","ax.plot([0, 1], [0, 1], 'k--')\n","ax.plot(test_loss, test_acc, 'bo', label='Test')\n","ax.set_xlabel('Loss')\n","ax.set_ylabel('Accuracy')\n","ax.set_title('Accuracy on test set: {:.2f}'.format(test_acc))\n","ax.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xkFtsKNXQzzU"},"outputs":[],"source":["#__________________________ EXPORT _____________________________________"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IEnDdEGnKKyz"},"outputs":[],"source":["pip install tensorflowjs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P4UsJTnPSxyN"},"outputs":[],"source":["model.save('my_model.h5')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tTuBqu-YV9Yv"},"outputs":[],"source":["import zipfile\n","\n","def compress_model(model_path, zip_path):\n","    with zipfile.ZipFile(zip_path, 'w') as zipf:\n","        zipf.write(model_path, arcname=model_path.split('/')[-1])\n","\n","model_path = 'my_model.h5'\n","zip_path = 'my_model.zip'\n","\n","compress_model(model_path, zip_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GwB57rikWDyG"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xNLDybsHWKuD"},"outputs":[],"source":["# Définissez le chemin d'accès dans Google Drive où vous souhaitez enregistrer le modèle\n","save_path = \"/content/drive/MyDrive/my_model.h5\"\n","\n","# Enregistrez le modèle\n","model.save(save_path)"]}],"metadata":{"accelerator":"GPU","colab":{"toc_visible":true,"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}